# scaffolding-modeling

ìŠ¤ìºí´ë”© ì‘ì—… ê³µìˆ˜ ì˜ˆì¸¡ì„ ìœ„í•œ CatBoost íšŒê·€ ëª¨ë¸ë§ í”„ë¡œì íŠ¸ì…ë‹ˆë‹¤.

## í”„ë¡œì íŠ¸ ê°œìš”

- **ëª¨ë¸**: CatBoost Regressor
- **ê²€ì¦**: K-fold Stratified Cross-Validation
- **ì „ì²˜ë¦¬**: ë°ì´í„° ëˆ„ìˆ˜ ë°©ì§€ë¥¼ ìœ„í•´ fold ë‚´ë¶€ì—ì„œ ìŠ¤ì¼€ì¼ë§/ì¸ì½”ë”© ìˆ˜í–‰
- **íŠœë‹**: Optuna ê¸°ë°˜ í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™”
- **í•´ì„**: SHAP ê¸°ë°˜ ë³€ìˆ˜ ì¤‘ìš”ë„ ë¶„ì„

---

## í´ë” êµ¬ì¡°

```
scaffolding-modeling/
â”œâ”€ data/                       # ì›ë³¸ ë°ì´í„°(ì§ì ‘ ì—…ë¡œë“œ í•„ìš”) ë° preprocess.pyì˜ ê²°ê³¼ë¬¼
â”œâ”€ src/
â”‚  â”œâ”€ preprocess.py            # ë°ì´í„° í´ë Œì§• + train/test ë¶„í• 
â”‚  â”œâ”€ train.py                 # 10-fold CV í•™ìŠµ + SHAP ë¶„ì„
â”‚  â”œâ”€ optimizer.py             # Optuna í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹
â”‚  â””â”€ utils.py                 # ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ (Metric, Logger êµ¬í˜„í˜„)
â”œâ”€ outputs/
â”‚  â”œâ”€ metrics.json             # ì„±ëŠ¥ ì¸¡ì • ê²°ê³¼ (train.pyì˜ ê²°ê³¼ë¬¼)
â”‚  â”œâ”€ test_predictions.csv     # í…ŒìŠ¤íŠ¸ ì˜ˆì¸¡ ê²°ê³¼ (train.pyì˜ ê²°ê³¼ë¬¼)
â”‚  â”œâ”€ shap_summary.png         # SHAP ë³€ìˆ˜ ì¤‘ìš”ë„ í”Œë¡¯ (train.pyì˜ ê²°ê³¼ë¬¼)
â”‚  â”œâ”€ best_params.json         # íŠœë‹ëœ í•˜ì´í¼íŒŒë¼ë¯¸í„° (optimizer.pyì˜ ê²°ê³¼ë¬¼)
â”‚  â”œâ”€ tuner_results.json       # íŠœë‹ ê²°ê³¼ ìš”ì•½ (optimizer.pyì˜ ê²°ê³¼ë¬¼)
â”‚  â””â”€ full_model.cbm           # ì „ì²´ í•™ìŠµ ë°ì´í„° ê¸°ë°˜ ìµœì¢… ëª¨ë¸ (train.pyì˜ ê²°ê³¼ë¬¼)
â”œâ”€ logs/                       # ë¡œê·¸ íŒŒì¼
â”œâ”€ requirements.txt            # ì˜ì¡´ì„± íŒ¨í‚¤ì§€ ëª©ë¡
â””â”€ README.md
```

---

## ğŸš€ Quick Start (ì „ì²´ ì›Œí¬í”Œë¡œìš°)

### Step 0. í”„ë¡œì íŠ¸ í´ë¡ 

```bash
git clone https://github.com/backnumber19/scaffolding-modeling.git
cd scaffolding-modeling
```

---

### Step 1. ê°€ìƒí™˜ê²½ ìƒì„± ë° íŒ¨í‚¤ì§€ ì„¤ì¹˜

#### Windows (PowerShell)

```powershell
python -3.11 -m venv .venv
.\.venv\Scripts\Activate.ps1
python -m pip install --upgrade pip
pip install -r requirements.txt
```

#### Linux

```bash
python3.11 -m venv .venv
source .venv/bin/activate
python -m pip install --upgrade pip
pip install -r requirements.txt
```

---

### Step 2. ì›ë³¸ ë°ì´í„° ì¤€ë¹„

`data/` í´ë”ì— ì›ë³¸ ì—‘ì…€ íŒŒì¼ì„ ë„£ìŠµë‹ˆë‹¤:

---

### Step 3. ì „ì²˜ë¦¬ (ë°ì´í„° í´ë Œì§• + Train/Test ë¶„í• )

```bash
python src/preprocess.py \
  --input {$YOUR_RAW_DATA_PATH} \
  --target-col SumOfManhoursProrate \
  --index-col TaskID \
  --test-size 0.2 \
  --seed 42 \
  --out-dir data \
  --log-dir logs
```

**ì¶œë ¥ íŒŒì¼:**
- `data/train.xlsx`, `data/test.xlsx`
- `data/train_target.xlsx`, `data/test_target.xlsx`
- `logs/preprocess.log`

> âš ï¸ ìŠ¤ì¼€ì¼ë§/ì›í•« ì¸ì½”ë”©ì€ ì—¬ê¸°ì„œ í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤ (ë°ì´í„° ëˆ„ìˆ˜ ë°©ì§€)

---

### Step 4. ì´ˆê¸° í•™ìŠµ (Baseline)

íŠœë‹ ì—†ì´ ê¸°ë³¸ íŒŒë¼ë¯¸í„°ë¡œ ë¨¼ì € í•™ìŠµí•©ë‹ˆë‹¤:

```bash
python src/train.py \
  --data-dir data \
  --out-dir outputs \
  --log-dir logs \
  --index-col TaskID \
  --seed 42 \
  --folds 10 \
  --iterations 2000 \
  --lr 0.05 \
  --depth 8 \
  --verbose 200
```

**ì¶œë ¥ íŒŒì¼:**
- `outputs/metrics.json` â€” ì„±ëŠ¥ ì§€í‘œ (RÂ², Adj.RÂ², MAE, RMSE, RAE)
- `outputs/test_predictions.csv` â€” í…ŒìŠ¤íŠ¸ ì˜ˆì¸¡ ê²°ê³¼
- `outputs/shap_summary.png` â€” SHAP ë³€ìˆ˜ ì¤‘ìš”ë„
- `outputs/full_model.cbm` â€” ì €ì¥ëœ ëª¨ë¸
- `logs/train.log`

---

### Step 5. í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ (Optuna)

Optunaë¡œ ìµœì ì˜ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ íƒìƒ‰í•©ë‹ˆë‹¤:

```bash
python src/optimizer.py \
  --data-dir data \
  --out-dir outputs \
  --log-dir logs \
  --index-col TaskID \
  --seed 42 \
  --folds 10 \
  --trials 100
```

**ì¶œë ¥ íŒŒì¼:**
- `outputs/best_params.json` â€” ìµœì  í•˜ì´í¼íŒŒë¼ë¯¸í„°
- `outputs/tuner_results.json` â€” íŠœë‹ ê²°ê³¼ ìš”ì•½
- `logs/tuner.log`

> ğŸ’¡ `--trials` ê°’ì„ ëŠ˜ë¦¬ë©´ ë” ë§ì€ ì¡°í•©ì„ íƒìƒ‰í•©ë‹ˆë‹¤ (ì‹œê°„ ì¦ê°€)

---

### Step 6. ìµœì¢… í•™ìŠµ (íŠœë‹ëœ íŒŒë¼ë¯¸í„° ì ìš©)

`best_params.json`ì´ ì¡´ì¬í•˜ë©´ ìë™ìœ¼ë¡œ ë¡œë“œë©ë‹ˆë‹¤(ì—†ìœ¼ë©´ ê¸°ë³¸ í•˜ì´í¼íŒŒë¼ë¯¸í„° ì ìš©):

```bash
python src/train.py \
  --data-dir data \
  --out-dir outputs \
  --log-dir logs \
  --index-col TaskID \
  --seed 42 \
  --folds 10 \
  --verbose 200
```

> `train.py`ëŠ” `outputs/best_params.json`ì„ ìë™ ê°ì§€í•˜ì—¬ ì ìš©í•©ë‹ˆë‹¤.

---

## ğŸ“Š ì„±ëŠ¥ ì¸¡ì • ë°©ì‹

`metrics.json`ì—ëŠ” ì„¸ ê°€ì§€ ì„±ëŠ¥ì´ ê¸°ë¡ë©ë‹ˆë‹¤:

| í•­ëª© | ì„¤ëª… |
|------|------|
| `val_mean` | 10-fold validation í‰ê·  ì„±ëŠ¥ |
| `test_mean` | 10ê°œ fold ëª¨ë¸ì˜ test ì˜ˆì¸¡ ì•™ìƒë¸” ì„±ëŠ¥ |
| `test_full_model` | ì „ì²´ train ë°ì´í„°ë¡œ í•™ìŠµí•œ ë‹¨ì¼ ëª¨ë¸ ì„±ëŠ¥ |

- **full_model RÂ²ê°€ ë” ë†’ìœ¼ë©´** â†’ `test_predictions.csv`ì— full_model ì˜ˆì¸¡ ì €ì¥
- **ê·¸ë ‡ì§€ ì•Šìœ¼ë©´** â†’ ì•™ìƒë¸” í‰ê·  ì˜ˆì¸¡ ì €ì¥

---

## ì£¼ìš” ì¸ì ì •ë¦¬

### preprocess.py

| ì¸ì | ê¸°ë³¸ê°’ | ì„¤ëª… |
|------|--------|------|
| `--input` | `data/FortillsDataset_JW_cleaned.xlsx` | ì›ë³¸ ë°ì´í„° ê²½ë¡œ |
| `--target-col` | `SumOfManhoursProrate` | íƒ€ê²Ÿ ì»¬ëŸ¼ëª… |
| `--index-col` | `TaskID` | ì¸ë±ìŠ¤ ì»¬ëŸ¼ëª… |
| `--test-size` | `0.2` | í…ŒìŠ¤íŠ¸ ë¹„ìœ¨ |
| `--seed` | `42` | ëœë¤ ì‹œë“œ |

### train.py

| ì¸ì | ê¸°ë³¸ê°’ | ì„¤ëª… |
|------|--------|------|
| `--data-dir` | `data` | ì „ì²˜ë¦¬ëœ ë°ì´í„° ê²½ë¡œ |
| `--out-dir` | `outputs` | ì¶œë ¥ ê²½ë¡œ |
| `--folds` | `10` | CV fold ìˆ˜ |
| `--iterations` | `2000` | CatBoost iterations |
| `--lr` | `0.05` | learning rate |
| `--depth` | `8` | tree depth |
| `--model-path` | `outputs/full_model.cbm` | ëª¨ë¸ ì €ì¥ ê²½ë¡œ |

### optimizer.py

| ì¸ì | ê¸°ë³¸ê°’ | ì„¤ëª… |
|------|--------|------|
| `--trials` | `100` | Optuna íƒìƒ‰ íšŸìˆ˜ |
| `--folds` | `10` | CV fold ìˆ˜ |

---

## ê¸°ìˆ ì  íŠ¹ì§•

1. **ë°ì´í„° ëˆ„ìˆ˜ ë°©ì§€**: ìŠ¤ì¼€ì¼ë§/ì›í•« ì¸ì½”ë”©ì€ ê° fold ë‚´ë¶€ì—ì„œ fit â†’ transform
2. **íƒ€ê²Ÿ ë³€í™˜**: `log1p(y)` ë³€í™˜ í›„ í•™ìŠµ, ì˜ˆì¸¡ ì‹œ `expm1(pred)` ì—­ë³€í™˜
3. **ì†ì‹¤ í•¨ìˆ˜**: MAE (ì´ìƒì¹˜ì— ê°•ê±´)
4. **CV ì „ëµ**: StratifiedKFold (íƒ€ê²Ÿ ë¶„í¬ ê· ë“±í™”)
5. **ë³‘ë ¬ íŠœë‹**: Optuna `n_jobs=-1`ë¡œ ë©€í‹°ì½”ì–´ í™œìš©
